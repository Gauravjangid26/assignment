{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d316ca5",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Q2. What are the different methods used for Web Scraping?\n",
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Q4. Why is flask used in this Web Scraping project?\n",
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67fc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285f8d7",
   "metadata": {},
   "source": [
    "web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.\n",
    "\n",
    "it is used-->\n",
    "There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format.\n",
    "\n",
    "used-->\n",
    "1. Price Monitoring\n",
    "Web Scraping can be used by companies to scrap the product data for their products and competing products as well to see how it impacts their pricing strategies. Companies can use this data to fix the optimal pricing for their products so that they can obtain maximum revenue.\n",
    "\n",
    "2. Market Research\n",
    "Web scraping can be used for market research by companies. High-quality web scraped data obtained in large volumes can be very helpful for companies in analyzing consumer trends and understanding which direction the company should move in the future. \n",
    "\n",
    "3. News Monitoring\n",
    "Web scraping news sites can provide detailed reports on the current news to a company. This is even more essential for companies that are frequently in the news or that depend on daily news for their day-to-day functioning. After all, news reports can make or break a company in a single day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf445ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384089e",
   "metadata": {},
   "source": [
    "Browser extensions Web Scrapers are extensions that can be added to your browser. These are easy to run as they are integrated with your browser, but at the same time, they are also limited because of this. Any advanced features that are outside the scope of your browser are impossible to run on Browser extension Web Scrapers. But Software Web Scrapers don’t have these limitations as they can be downloaded and installed on your computer. These are more complex than Browser web scrapers, but they also have advanced features that are not limited by the scope of your browser.\n",
    "\n",
    "Cloud Web Scrapers run on the cloud, which is an off-site server mostly provided by the company that you buy the scraper from. These allow your computer to focus on other tasks as the computer resources are not required to scrape data from websites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12f7d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7590f90d",
   "metadata": {},
   "source": [
    "BeautifulSoup is used extract information from the HTML and XML files. It provides a parse tree and the functions to navigate, search or modify this parse tree.\n",
    "\n",
    "Beautiful Soup is a Python library used to pull the data out of HTML and XML files for web scraping purposes. It produces a parse tree from page source code that can be utilized to drag data hierarchically and more legibly. \n",
    "It was first presented by Leonard Richardson, who is still donating to this project, and this project is also supported by Tide lift \n",
    "\n",
    "used-->\n",
    "\n",
    "1. Beautiful Soup provides a few simple methods and Pythonic phrases for guiding, searching, and changing a parse tree: a toolkit for studying a document and removing what you need. It doesn’t take much code to document an application.\n",
    "\n",
    "2. Beautiful Soup automatically converts incoming records to Unicode and outgoing forms to UTF-8. You don’t have to think about encodings unless the document doesn’t define an encoding, and Beautiful Soup can’t catch one. Then you just have to choose the original encoding.\n",
    "\n",
    "3. Beautiful Soup sits on top of famous Python parsers like LXML and HTML, allowing you to try different parsing strategies or trade speed for flexibility.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5cb2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575bebad",
   "metadata": {},
   "source": [
    "flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920318e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d672a3",
   "metadata": {},
   "source": [
    "Elastic beanstalk\n",
    "usesd-->\n",
    "Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to application health monitoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8769a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
